---
{"dg-publish":true,"permalink":"/1 Stories of Bizzo's Life/1 数学/7 概率论与随机微积分/","tags":["#概率论与统计学"]}
---


> [!abstract] 关键词
> - 积分与测度
> - 概率与期望
> - [[1 Stories of Bizzo's Life/1 数学/随机过程\|随机过程]]
> - 鞅
> - 停时的分类
> - 循序、可选、可料$\sigma$-代数
> - 随机微积分

## 测度与积分
主要考虑积分与测度论在概率论中的应用。参考书包括[[Renjiagang2021,cohen2015stochastic,lieb2001Analysis\|Renjiagang2021,cohen2015stochastic,lieb2001Analysis]]
> [!definition]
> - {$\sigma$-代数和可测空间}
>   Let $S$ be a set. A collection of subsets $\Sigma$ of $S$ is called a **(Boolean) algebra** of $S$ (or field of subsets of $S$ ) provided
>   \begin{enumerate}[(1)]
> - $\emptyset \in \Sigma$,
> - if $A \in \Sigma$ then $A^{c}:=S \backslash A \in \Sigma$,
> - if $m \in \mathbb{N}$ and $A_{n} \in \Sigma$ for $n=1,2, \ldots, m$ then $\bigcup_{n=1}^{m} A_{n} \in \Sigma$.
>   \end{enumerate}
>   If, furthermore, (3) can be strengthened to
>   (3') if $A_{n} \in \Sigma$ for $n=1,2, \ldots$, then $\bigcup_{n=1}^{\infty} A_{n} \in \Sigma$.
>   then $\Sigma$ is called a **$\sigma$-algebra** (or $\sigma$-field) on $S$. If $\Sigma$ is a $\sigma$-algebra on $S$, then the pair $(S, \Sigma)$ is called a **measurable space**.

> [!definition]
> - {Borel $\sigma$-代数}
>   $(S,\mathscr{T})$是拓扑空间，由开集生成的$\sigma$-代数称为**Borel代数**，记为$\mathcal{B}(S)$，它的元素称为**Borel集**。

> [!note]
> - Borel $\sigma$-代数将$\sigma$-代数同拓扑结合在一起。

> [!definition] 单调类(Monotone class)

> [!theorem] Theorem 单调类定理
>   $\mathcal{N}$是集合$S$的子集构成的代数\footnote{代数要求差和并在集合中，不必是$\sigma$-代数}，$\mathcal{M}$是包含$\mathcal{N}$的单调类，则$\mathcal{M}$包含了由$\mathcal{N}$生成的$\sigma$-代数$\sigma(\mathcal{N})$，且$\sigma(\mathcal{N})$是包含$\mathcal{N}$的最小单调类。

> [!definition]
> - {测度空间}
>   $\Sigma$是$S$的子集构成的$\sigma$-代数，配备了可数可加的非负函数$\mu$的可测空间$(S,\Sigma)$称为**测度空间**，记为$(S,\Sigma,\mu)$，$\mu$称为**测度**。如果$\mu(\Omega)=1$，那么称$\mu$为**概率测度**。

> [!definition]
> - {完备测度空间}
>   如果测度空间$(S,\Sigma,\mu)$包含了任意零测集的任意子集，那么称它为**完备**测度空间。

> [!definition] 可测函数
>   Suppose $(S, \Sigma)$ and $(E, \mathcal{E})$ are both measurable spaces. $A$ function $f: S \rightarrow E$ is called **$\Sigma / \mathcal{E}$ - measurable if $f^{-1}(B) \in \Sigma$ for every $B \in \mathcal{E}$.
>   If $\Sigma$ is a Borel $\sigma$-algebra on $S$, then $f$ is said to be **Borel measurable**.

> [!note]
> - $f$的原像保持$\sigma$-代数，则称$f$可测。

> [!theorem] Theorem 分布函数与Baire测度的一一对应
>   右连续的非减函数$F$(称为**分布函数**)与$(\mathbb{R}, \mathcal{B}(\mathbb{R}))$上的测度$\mu$\\(称为**Baire测度**或**Lebesgue-Stieltjes测度**)之间存在一一对应关系。
>
$$
\mu(] a, b])=F(b)-F(a)
$$
> [!note]
> - 基于这种对应，关于由$F$诱导的测度$\mu$的积分可以写成两种形式
>
$$
\int_{A} f d \mu=\int_{A} f d F
$$
定义Lebesgue积分一般都会经历以下几个步骤：
\begin{itemize}
    \item 定义简单函数在测度空间$(S,\Sigma,\mu)$上的全空间积分。
    \item 定义非负可测函数在$S$上的积分。
    \item 将一般可测函数拆成两个非负部分，分别定义他们在$S$上的积分。
    \item 定义一般的可测函数在$A\subset S$上的积分。
\end{itemize}
> [!definition]
> - {Signed Measure}
>   可数可加的定义在集组上的函数如果可正可负，但只取$\pm \infty$中的一个值，那么称其为**带符号的测度**。

> [!definition]
> - {有界变差函数(Functions of Bounded Variation)}
>   对于右连续函数$f:[0, \infty[\rightarrow \mathbb{R}$，如果任取一个递增序列$\left\{t_{i}\right\}_{i \in \mathbb{N}} \subset[0, T]$，$T \in[0, \infty[$，都有
>
$$
\sum_{i}\left|f\left(t_{i+1}\right)-f\left(t_{i}\right)\right|<\infty
$$
>   那么称$f$具有**有限变差或有界变差**。

> [!note]
> - 右连续的有限变差函数$f$都可以拆成两个右连续的非减函数（即，分布函数），满足$f=g-h$。

> [!theorem] Theorem
> - 右连续的有限变差函数与$\mathcal{B}(\mathbb{R})$上的有限的带符号测度之间存在一一对应关系。

## 概率与期望
测度论对“概率”这一概念进行了公理化，提供了坚实的数学基础。这种方法可以避免许多与概率相关的哲学困难，但另一方面，它只提供了一个数学框架而没有解释概率的确切含义。无论是频率论还是贝叶斯观点或者其他哲学观点，在数学方面基本相同。
### 概率空间
> [!definition]
> - 实验的可能结果$\omega$的集合$\Omega$称为**样本空间**，$\Omega$的$\sigma$-代数 $\mathcal{F}$ 称为**事件空间**，其中的元素称为**事件**。

> [!note]
> - 为什么需要$\sigma$-代数的结构呢？这是为了一致地定义事件的概率和期望，所有可能的事件都被包含在$\sigma$-代数$\Omega$中，他指定了所有可以定义概率的事件，也即那些能够判断是否发生了的事件。当我们在某次试验中得到结果$\omega$，那么当$\omega\in A\subset \Omega$时，称事件$A$发生了，我们可以用概率测度来定义事件$A$发生的概率，为了定义事件$A$没有发生的概率、事件$A$或者$B$至少有一个发生的概率，我们必须要求$A^c$和$A\cup B$也处在可以判断是否发生之列，类似的考虑最终导致了$\sigma$-代数。简单的数学概念往往有着明确的动机，而我当面对那些繁复的定义时，往往难以捉摸其创造者的巧思。
>   另外，在统计学中，定义充分统计量(sufficient statistic)也需要用到$\sigma$-代数。

> [!definition] 概率空间
>   A triple $(\Omega, \mathcal{F}, P)$, where $\Omega$ is a set, $\mathcal{F}$ a $\sigma$-algebra of sub-sets of $\Omega$ and $P$ a probability measure on $\mathcal{F}$, is called a **probability space** or probability triple.

> [!note]
> - 指定概率测度相当于指定了随机变量的分布。 例如定义$(\mathbb{R}, \overline{\mathcal{B}}(\mathbb{R}), P)$中
>
$$
P(A)=\int_{A} \frac{1}{\sqrt{2 \pi}} e^{-x^{2} / 2} d x
$$
>   相当于指定了随机变量$X$服从正态分布。
>   定义$([0,1], \mathcal{B}([0,1]), P)$中的$P$为$P(] a, b])=b-a$相当于指定了随机变量服从均匀分布。

> [!definition]
> - {随机变量、期望和(累积)分布函数}
>   从概率空间$(\Omega, \mathcal{F}, P)$到可测空间$(E, \mathcal{E})$的可测函数$X$称为**$E$值随机变量**。当$(E, \mathcal{E})=(\overline{\mathbb{R}}, \mathcal{B}(\overline{\mathbb{R}}))$时，称$X$为**随机变量**。
>   $E$值随机变量$X$关于测度$P$的在全空间中的积分称为$X$的**期望**，记作
>
$$
E[X]=\int_{\Omega} X(\omega) d P(\omega)
$$
>   $P$和$X$可以诱导$(E, \mathcal{E})$上的一个概率测度，
>
$$
P^{X}(A)=P \circ X^{-1}(A)=P(\{\omega: X(\omega) \in A\}),\quad \forall A\in \mathcal{E}
$$
>   若$(E, \mathcal{E})=(\mathbb{R}, \mathcal{B}(\mathbb{R}))$，则称
>
$$
F_X(a)=P(X\le a)=E[I_{\{X\le a\}}]
$$
>   为$X$的**(累积)分布函数**或**分布律**。该定义同前述分布函数的定义是一致的。

> [!note]
> - 从以上的定义可以看出随机变量是定义在 $(\Omega, \mathcal{F}, P)$上的东西，而不是仅仅定义在可测空间 $(\Omega, \mathcal{F})$上，也就是说，只要改变概率测度，就得到完全不同的随机变量，随机变量的分布函数是由它的概率空间上的概率测度确定的。随机过程也是如此。
>   随机变量的期望就是它在整个样本空间的平均值，已知某个事件$A$的条件期望就是随机变量在$A$上的平均值。
>   比较同一个可测空间上的两个随机变量的大小，可以比较它们在每个样本上的取值的大小，也可以比较它们在每个事件上的积分值的大小。

> [!lemma] 特征函数
>   随机变量$X$的分布函数由特征函数$\phi_{X}(t)$唯一确定
>
$$
\phi_{X}(t)=E\left[e^{i t X}\right]
$$
> [!proof]
> -
$$
F_{X}(x)=\frac{1}{2}-\frac{1}{\pi} \int_{0}^{\infty} \frac{\operatorname{Im}\left[e^{-i t x} \varphi_{X}(t)\right]}{t} d t
$$
>   或者利用
>
$$
F_{X}(b)-F_{X}(a)=\frac{1}{2 \pi} \lim \limits_{T \rightarrow \infty} \int_{-T}^{+T} \frac{e^{-i t a}-e^{-i t b}}{i t} \varphi_{X}(t) d t
$$
>   取两个数列$\{a_n\}\rightarrow -\infty$和$\{b_n\}\rightarrow b$即得$F_X(b)$

给定一个概率空间，依次可以定义事件的有限大集族$\left\{A_{n}\right\}_{n=1}^{m}$、事件的任意大集族$\left\{A_{\lambda}\right\}_{\lambda \in I}$、$\sigma$-代数的有限大集族$\left\{\mathcal{F}_{n}\right\}_{n=1}^{m}$、$\sigma$-代数的任意大集族$\left\{\mathcal{F}_{\lambda}\right\}_{\lambda \in I}$的独立性。以最简单的集族$\{A,B\}$为例，如果
$$
P(A\cap B )=P(A)P(B)
$$
那么称集族$\{A,B\}$是**独立**的。 更进一步，根据事件的独立性可以定义随机变量的独立性。
> [!definition]
> - {随机变量的独立性}
>   A collection of $E$-valued random variables $\left\{X_{i}\right\}$ is called **independent** if, for every $A, B \in \mathcal{E}$, the events $X_{i}^{-1}(A), X_{j}^{-1}(B)$ are independent for all $i \neq j$.

> [!lemma]
> - {Borel–Cantelli}
>   $\left\{A_{n}\right\}_{n \in \mathbb{N}}$是$\sigma$-代数中的集序列，如果$\sum_{n} \mu\left(A_{n}\right)<\infty$，那么集序列的上极限为零，即
>
$$
\mu \left(\limsup _{n \rightarrow \infty} A_{n}\right)=\mu \left(\bigcap_{n=1}^{\infty} \bigcup_{k=n}^{\infty} A_{k}\right)=0
$$
> [!note]
> - 该定理可以解释为，如果事件集的概率的和是有限的，那么$\left\{A_{n}\right\}_{n \in \mathbb{N}}$中无穷多个事件出现的概率零。

> [!proof]
> -
$$
\mu\left(\bigcap_{n} \bigcup_{k \geq n} A_{k}\right) \leq \inf _{n} \mu\left(\bigcup_{k \geq n} A_{k}\right) \leq \inf _{n} \sum_{k\geq n} \mu\left(A_{k}\right)=0
$$
>   第一个不等号利用了测度的非负性，第二个不等号利用了可加性和非负性，最右侧的等号是由于级数$\sum \mu(A_n)$收敛。

### 条件概率和给定事件的条件期望
下面考虑条件概率，给定概率空间$(\Omega, \mathcal{F}, P)$，如果已知事件$A$发生了，那么可以在原有的可测空间上构造一个新的概率测度$P_A(\cdot)\equiv P(\cdot|A)=P(A\cap \cdot )/P(A)$。
得到一个新的概率空间$(\Omega, \mathcal{F}, P_A)$。

关于条件概率有几个重要的公式。
> [!proposition]
> -
$$
\text{乘法公式}\quad P(A \cap B)=P(A) P(B | A)=P(B) P(A | B)
$$
>
$$
\text{全概率公式}\quad P(A)=\sum_{k} P\left(B_{k}\right) P\left(A | B_{k}\right)
$$
>
$$
\text{贝叶斯公式}\quad P\left(B_{k} | A\right)=\frac{P\left(B_{k}\right) P\left(A | B_{k}\right)}{\sum_{n} P\left(B_{n}\right) P\left(A | B_{n}\right)}
$$
>   其中事件$A \subset \sum_{k} B_{k}$，$B_k$的测度均大于零。

> [!definition]
> - {给定事件的条件期望}
>   $X$是条件概率空间$(\Omega, \mathcal{F}, P_A)$上的随机变量，称
>
$$
E[X|A]=\int_{\Omega} X(\omega) d P_A(\omega)=\frac{1}{P(A)}\int_{A} X(\omega) d P(\omega)
$$
>   为$X$关于给定事件$A$的**条件期望**。

> [!note]
> - 给定事件的条件概率可以视为给定事件的条件期望的特殊情形
>
$$
P(B | A)=\frac{P(A \cap B)}{P(A)}=\frac{\int_{A} I_{B} d P}{P(A)}=\int_{\Omega} I_{B} d P_{A}=E\left[I_{B} | A\right]
$$
### 给定子$\sigma$-代数的条件期望
下面的关于条件概率的推广的引入主要整理自[[Yan2009\|Yan2009]]的第五章。

把条件概率视为定义在样本空间上的函数（即，随机变量），吃进去一个$\omega\in\Omega$，返回一个期望值。例如，当同时考虑$E(X|A)$和$E(X|A^c)$时，不是将他们理解为孤立的两个数，而是理解为函数，当$\omega\in A$时，返回$X$在$A$上的平均值，当$\omega\in A^c$时，返回$X$在$A^c$上的平均值。这一理解可以推广到样本空间$\Omega$的任意划分，将
$$
\sum_{n} E\left(X | A_{n}\right) I_{A_{n}}(\omega)
$$
视为一定意义下的条件期望，称为给定$\mathcal{E}=\sigma(\{A_n\})$\footnote{用$\{A_n\}$生成的$\sigma$-代数}之下的条件期望，记为$E(X|\mathcal{E})$，这就是条件期望的构造性定义。注意$E(X|\mathcal{E})$与$X$本身的区别，$E(X|\mathcal{E})$是$X$的“粗粒化”\footnote{$\sigma$-代数关于包含关系构成怎样的序结构？是否也能定义粗细？}。 
$E(X|\mathcal{E})$能给出$\mathcal{E}$中任意事件$A$的期望，若$A\in \mathcal{E}$，则$A$是$\{A_n\}$中某些元素的不交并，
于是可以推得
$$
E(X | A)=\frac{1}{P(A)} \int_{A} E(X |\mathcal{E}) d P
$$
上式称为条件期望的描述性定义，区别于前面的构造性定义。构造性定义更具可操作性，找到$\sigma$子代数的划分后，就可以就可以将其直接作用到样本空间的元素上。描述性定义能够在证明条件期望的性质时提供便利。
> [!definition]
> - {给定子$\sigma$-代数的条件期望}
>   $X$是概率空间$(\Omega, \mathcal{F}, P)$上的实值可积随机变量，$\mathcal{E}\subset \mathcal{F}$是$\mathcal{F}$的$\sigma$的子代数，
>   $Y$是$\mathcal{E}$可测的可积随机变量，若$Y$满足
>
$$
(P(A)E[X|A]=E\left[I_{A} X\right]=)\int_{A} X d P=\int_{A} Y d P(=E\left[I_{A} Y\right])\quad \forall A\in \mathcal{E}
$$
>   则称$Y$为$X$的给定$\mathcal{E}$的条件期望，记作$E(X|\mathcal{E})$。

> [!note]
> - 定义的合理性？给定$\omega\in \Omega$如何计算$E(X|\mathcal{E})(\omega)$？使用哪个$A_n$来计算$E\left(X | B_{n}\right)$？不同的划分会导致不同的条件期望？不同的划分意味着不同的子$\sigma$-代数。

> [!theorem] Theorem
> - 设$\mathcal{E}\subset \mathcal{F}$，则任取$X \in L^{1}$，条件概率$E(X|\mathcal{E})$存在且在等价\footnote{若$P(X\ne Y)=0$，则称$X$和$Y$等价}意义下唯一。

> [!note]
> - 利用了Radon–Nikodym定理。

下面讨论条件期望的一些性质。

补充给定$\sigma$-代数的条件概率和给定随机变量的条件概率？

### 一致可积性 Uniform integrability

### 正则条件概率 Regular conditional probability

## 随机过程

### Filtration and Stopping Times
为了在概率空间中引入时间，记录和描述随机变量的发展历程，需要考虑随时间变化的一族子$\sigma$-代数。
> [!definition]
> - {Filtration}
>   可测空间 $(\Omega, \mathcal{F})$的**filtration**是$\mathcal{F}$的一族子$\sigma$-代数，满足若$s<t$则$\mathcal{F}_{s} \subseteq \mathcal{F}_{t}$。
>   配备了filtration的概率空间 $(\Omega, \mathcal{F}, \left\{\mathcal{F}_{t}\right\}_{t \in \mathbb{T}}, P)$称为**filtered probability space**。

> [!note]
> - 至此，概率论中已经出现了三层集合
>   \begin{enumerate}[(1)]
> - 事件是样本的集合。
> - 事件空间作为$\sigma$-代数，是事件的集合。
> - filtration是子$\sigma$-代数的集合。
>   \end{enumerate}
>   在中山大学，我们称filtration为$\sigma$-代数流[[Renjiagang2021\|Renjiagang2021]]。
>   子$\sigma$-代数是不对$\Omega$取子集的，如何理解存在一些不能确定是否发生了的事件？下面以重复抛两次硬币的随机过程为例，显式地写出样本空间$\Omega$、事件空间$\mathcal{F}$和该随机过程的自然filtration$\{\mathcal{F}_0,\mathcal{F}_1,\mathcal{F}_2\}$\footnote{举例是否正确？定义\ref{def:naturalfil} }
>
$$
\Omega=\{0,1\}\times\{0,1\}\equiv\{00,01,10,11\}
$$
>   \begin{multline*}
>   \mathcal{F}= 2^\Omega =\{\varnothing ,\{00\},\{01\},\{10\},\{11\},\{00,01\},\{00,10\},\{00,11\},\{01,10\},\{01,11\},\{10,11\},\\
>   \{00,01,10\},\{00,01,11\},\{00,10,11\},\{01,10,11\},\Omega \}
>   \end{multline*}
>
$$
\begin{aligned}
\mathcal{F}_0&=\{\varnothing,\Omega\}\\
\mathcal{F}_1&=\sigma(\{00,01\},\{10,11\})\\
\mathcal{F}_2&=\mathcal{F}
\end{aligned}
$$
>   在概率空间 $(\Omega, \mathcal{F}_1, P)$中，我们无法计算类似“第二次抛硬币结果为1”或者“两次抛硬币的结果分别为01”这样的事件的概率，因为它不在事件空间内，我们无法判断它是否发生了。

> [!definition] 右连续filtration
>   定义$t$时刻的一瞬之后的filtration
>
$$
\mathcal{F}_{t+}=\bigcap_{s>t} \mathcal{F}_{s}
$$
>   以及严格早于$t$的filtration
>
$$
\mathcal{F}_{t-}=\bigvee_{s<t} \mathcal{F}_{s}
$$
>   其中$\bigvee_{n} \Sigma_{n}:=\sigma\left(\bigcup_{n} \Sigma_{n}\right)$。
>   如果
$$
\mathcal{F}_{t}=\mathcal{F}_{t+}\quad \forall t\in \mathbb{T}
$$
>   则称$\mathcal{F}$为**右连续**filtration。

> [!note]
> - $\mathcal{F}$通常被解释为“信息”，$\mathcal{F}_t$被解释为$t$时刻的“信息”，根据右连续的定义，在下一时刻的$\mathcal{F}_{t+}$没有变得更大，因此右连续可以解释为下一时刻没有更多的“可用信息”。

> [!definition]
> - {停时 Stopping time}
>   设可测空间 $(\Omega, \mathcal{F})$上有Filtration$\left\{\mathcal{F}_{t}\right\}_{t \in \mathbb{T}}$，称随机变量$T: \Omega \rightarrow \mathbb{T} \cup\{\infty\}$为**随机时间**。若随机时间满足
>
$$
\{T \leq t\}\equiv\{\omega: T(\omega) \leq t\} \in \mathcal{F}_{t} \quad  \forall t \in \mathbb{T}
$$
>   则称其为关于Filtration$\left\{\mathcal{F}_{t}\right\}_{t \in \mathbb{T}}$的**停时**。对一个停时$T$，定义**$T$前$\sigma$-代数**\footnote{**到时间$T$时已经出现的事件的$\sigma$-代数**}
$$
\mathcal{F}_{T}=\{A\in \mathcal{F}\mid A \cap\{T \leq t\} \in \mathcal{F}_{t},\;\forall t\in \mathbb{T}\}
$$
> [!note]
> - 从直观上来说，设$T$表示某个事件发生的时刻，若在任意固定的时刻$t$，我们能够根据现在已经拥有的全部信息$\left\{\mathcal{F}_{t}\right\}_{t \in \mathbb{T}}$来判断这个事件是否已经到来，而不需要依赖未来的信息，那么$T$就是停时。例如，重复抛硬币，比方说重复$n$次，出现第三次正面的时刻是停时，而倒数第二次出现反面的时刻不是停时。
>   在此基础上，$\mathcal{F}_T$中包含了那些在达到停时$T$（而不是在某个确定的时刻）就能知道是否发生的事件，而不包含那些不知道是否发生了的事件。例如，重复抛硬币，直到第二次出现正面，那么在停时$T$，我们能够知道此前一共有几个反面出现，但是这不意味着在任意给定的时刻$t$我们能知道这一点，除非我们知道$t$在停时之后。根据停时的形式可以证明 $\mathcal{F}_{T}$是$\sigma$-代数。

下面讨论关于停时的性质和定理。

> [!lemma]
> - 设$T$是关于filtration $\left\{\mathcal{F}_{t}\right\}_{t \in \mathbb{T}}$ 的停时，则$\{T<t\} \in \mathcal{F}_{t}\; \forall t$。
>   反之，若$\{T<t\} \in \mathcal{F}_{t},\; \forall t$且filtration $\left\{\mathcal{F}_{t}\right\}_{t \in \mathbb{T}}$右连续，那么$T$是停时。

> [!proof]
> - $T$是停时，因此
$$
\left\{T \leq t-\frac{1}{n}\right\} \in \mathcal{F}_{t-\frac{1}{n}} \subseteq \mathcal{F}_{t}\; \forall n\geq 1
$$
>
$$
\{T<t\}=\bigcup_{n=1}^{\infty}\left\{T \leq t-\frac{1}{n}\right\}\in \mathcal{F}_t
$$
>   反之，由于
$$
\{T \leq t\} \in \mathcal{F}_{t+\epsilon}
$$
>   故
$$
\{T \leq t\}\in \bigcap_{\epsilon >0}\mathcal{F}_{t+\epsilon}= \mathcal{F}_{t+}\mathcal{F}_t
$$
> [!lemma]
> - {用停时构造新的停时}
>
$$
S \wedge T=\min \{S, T\}
$$
>
$$
S \vee T=\max \{S, T\}
$$
>
$$
\bigvee_{n} T_{n}=\sup _{n}\left\{T_{n}\right\}
$$
>
$$
\bigwedge_{n} T_{n}=\inf _{n}\left\{T_{n}\right\}
$$
>   都是停时

> [!theorem] Theorem
> - $S$和$T$是关于$\left\{\mathcal{F}_{t}\right\}_{t \in \mathbb{T}}$的停时，
>   \begin{enumerate}[(1)]
> - 若$S\leq T$，则$\mathcal{F}_{S} \subseteq \mathcal{F}_{T}$
> - $A \in \mathcal{F}_{S}$ ，则$A \cap\{S \leq T\} \in \mathcal{F}_{T}$
>   \end{enumerate}

> [!proof]
> - \begin{enumerate}[(1)]
> - 由于$S\leq T$，故$\{T \leq t\} \subset \{S \leq t\}$，进而对$A\in \mathcal{F}_S$
>
$$
A \cap\{T \leq t\}=A \cap\{S \leq t\} \cap\{T \leq t\} \in \mathcal{F}_{t}
$$
>   根据$\mathcal{F}_T$的定义
>
$$
A\in F_T
$$
> -
$$
\begin{aligned} A \cap\{S \leq T\} & \cap\{T \leq t\} \\ & =(A \cap\{S \leq t\}) \cap\{T \leq t\} \cap\{S \wedge t \leq T \wedge t\} .\end{aligned}
$$
>   其中的每一项都在$\mathcal{F}_t$内，第三项是由于$S \wedge t$和$T \wedge t$都是$\mathcal{F}_t$-可测的随机变量。（如何证明？）
>   \end{enumerate}

> [!theorem] Theorem
> - {随机时间的随机变量}
>   设时间指标集$\mathbb{T}=\{0,1, \ldots, \infty\}$ 和 可测空间$(\Omega, \mathcal{F})$上有离散时间的filtration$\left\{\mathcal{F}_{n}\right\}_{n \in \mathbb{T}}$，如果随机过程$X$是适应过程(定义\ref{def:stoprocess})，即随机变量族$\left\{X_{n}\right\}_{n \in \mathbb{T}}$中的每个$X_n$都是$\mathcal{F}_n$可测的，那么随机变量$X_T=X_{T(\omega)}(\omega)$是$\mathcal{F}_T$可测的。

> [!proof]
> - 要证明$X_T=X_{T(\omega)}(\omega)$是$\mathcal{F}_T$可测的，只要证
>
$$
\left\{X_{T} \in A\right\} \in \mathcal{F}_{T}\quad \forall A \in \mathcal{B}(\mathbb{R})
$$
>   根据$\mathcal{F}_T$的定义，只要证
$$
\left\{X_{T} \in A\right\} \cap\{T \leq n\} \in \mathcal{F}_{n}\quad \forall n \in \mathbb{T}
$$
>   注意到
>
$$
\left\{X_{T} \in A\right\} \cap\{T \leq n\}=\bigcup_{k=1}^{n}\left\{X_{T} \in A\right\} \cap\{T=k\}
$$
>   并集中的每一项都有
>
$$
\left\{X_{T} \in A\right\} \cap\{T=k\} =\{X_k\in A\}\in \mathcal{F}_{k} \subset \mathcal{F}_{n}
$$
> [!note]
> - 循序可测性能够将该定理推广到连续时间情形。

> [!definition]
> - {随机过程及其时空可测性}\label{def:stoprocess}
>   \begin{enumerate}[(1)]
> - 有两个可测空间$(\Omega, \mathcal{F}),\;(E, \mathcal{E})$和时间指标集$\mathbb{T}$，称一族由$t\in \mathbb{T}$索引的$E$-值随机变量$\left\{X_{t}\right\}_{t \in \mathbb{T}}$为定义在 $(\Omega, \mathcal{F})$上的取值于$(E,\mathcal{E})$的**随机过程**，$\left\{X_{t}\right\}_{t \in \mathbb{T}}$简记为$X$，相当于将其视为映射$X: \mathbb{T} \times \Omega \rightarrow E$。
>   称$(\Omega, \mathcal{F})$为$X$的**底空间(base space)**，称 $(E,\mathcal{E})$为$X$的**状态空间(state space)**。
>   $\forall t\in \mathbb{T}$，$X_t$是$X$在$t$时刻的**状态(state)**。
>   给定$\omega \in \Omega$,称集合$\left\{X_{t}(\omega) ; t \in \mathbb{T}\right\}$为$\omega$的**样本曲线(sample path)**或**轨迹(trajectory)**。
> - 设$\left\{\mathcal{F}_{t}\right\}_{t \in \mathbb{T}}$是可测空间 $(\Omega, \mathcal{F})$上的filtration，如果$\forall t\in \mathbb{T}$，状态$X_t$都是$\mathcal{F}_t$可测的，那么称$X$是**适应过程**。
> - 设$\mathbb{T}=[0, \infty[$ or $\mathbb{T}=[0, \infty]$，如果随机过程$X:(t, \omega) \mapsto X_{t}(\omega)$是$\mathcal{B}(\mathbb{T}) \otimes \mathcal{F}$-可测的，那么称$X$是**可测过程**。其中**积空间的$\sigma$-代数**的定义为$\Sigma_{1} \otimes \Sigma_{2}:=\sigma\left\{A \times B: A \in \Sigma_{1}\right.$ and $\left.B \in \Sigma_{2}\right\}$
> - 设$\mathbb{T}=[0, \infty[$ or $\mathbb{T}=[0, \infty]$，如果映射
$$
X:(s, \omega) \mapsto X_{s}(\omega),[0, t] \times \Omega\rightarrow E
$$
>   是$\mathcal{E}$可测的，其中$[0, t] \times \Omega$被赋予积$\sigma$-代数$\mathcal{B}([0, t]) \otimes \mathcal{F}_{t}$，\\那么称$X$是**循序可测(progressively measurable)**的或**循序(progressive)**的。
>   \end{enumerate}

> [!note]
> - 适应过程定义了$X_t(\omega)$作为$\omega$的函数的可测性，即空间可测性，通常将适应过程阐释为，对任意$t$，我们知道$X_t$的值（？）。
>   循序可测性推广了离散版本的定理，定义了结合了随机过程的filtration和时空可测性，帮助我们在连续时间情形下定义随机时间的随机变量。

> [!definition]
> - 源于法语的随机过程（的轨迹）的性质
>   càdlàg:\,右侧连续，左侧极限存在（注意与filtration的右连续相区分。）。
>   càglàd:\,左侧连续，右侧极限存在。
>   其中c是连续，l是极限存在，d是右，g是左。

\begin{figure}[htbp]
 \centering
 \includegraphics[width=0.4\textwidth]{image//2023-04-30-20-42-15.png}
 \caption{ 分布函数是càdlàg函数 }
 \label{  }
\end{figure}

> [!definition]
> - {随机过程的等价性}
>   设 $X, Y$ 是定义在同一个概率空间上的两个过程.
>   (1) 若 $\forall t \in \mathbb{T}, X_{t}=Y_{t}$ a.s., 则称 $X$ 和 $Y$ 随机等价, 或互为**修正(modification)**.
>   (2)若 $P\left(X_{t}=Y_{t}, \forall t \in \mathbb{T}\right)=1$, 则称 $X$ 与 $Y$ **无区别(indistinguishible)**.

考虑适应过程和停时的关系。
> [!definition]
> - {自然filtration}\label{def:naturalfil}
>   在 $(\Omega, \mathcal{F}, P)$上有取值于$(E,\mathcal{E})$的随机过程$X$，那么$X$关于filtration$\left\{\mathcal{F}_{t}^{X}\right\}$一定是适应过程，其中
>
$$
\mathcal{F}_{t}^{X}=\sigma\left\{X_{s}: s \leq t\right\}=\sigma\left\{X_{s}^{-1}(A) \mid s \in I, s \leq t, A \in \mathcal{E}\right\}
$$
>   称该filtration为**$X$的自然filtration**或者**由$X$生成的filtration**。

> [!note]
> - 自然filtration可以通过加入$\mathcal{F}$中的零测集被“完备化”（测度空间的完备化）且可以用右连续的$\mathcal{F}_{t+}^{X}$代替不一定右连续的$\mathcal{F}_{t}^{X}$。
>   $\Omega$是试验的可能结果的样本空间的直积，$X_n$的取值只与第$n$个slot的样本有关。以前述抛两次硬币的随机过程为例，
$$
X^{-1}_1(\{0\})=\{00,01\}\quad X^{-1}_1(\{1\})=\{10,11\}
$$
>   因此
>
$$
\mathcal{F}_1=\sigma(\{00,01\},\{10,11\})
$$
> [!theorem] Theorem
> - {Kolmogorov拓展定理}

### 功率谱密度

> [!definition] (Power) Spectral Density
>   对宽平稳\footnote{期望不随时间变化且关联函数时间平移不变（关联函数只与时间差有关）。对马尔科夫链，宽平稳$\Rightarrow$时齐次。}的随机过程$y(t)$的轨迹可以定义其**功率谱密度(PSD)**
>
$$
S_{y}(\omega) \equiv \lim \limits_{T \rightarrow \infty} \frac{1}{2\pi T}\left|\int_{-T / 2}^{+T / 2}[y(t)-\bar{y}] e^{i \omega t} d t\right|^{2}\equiv\lim \limits_{T \rightarrow \infty} \frac{|\hat{y}_T(\omega)|^2}{2\pi T}
$$

> [!note]
> - 这是双边的功率谱密度，实际上是一个偶函数，有时将它折叠成单边的PSD，$S_{y}^{\mathrm{sigle}}(\omega)=2S_{y}(\omega),\omega>0$ 
>   对于确定的信号或者随机过程的实现，上式可以直接计算，并且具有明显的物理含义，对$y(t)-\bar{y}$ 做Fourier级数展开
>
$$
\begin{aligned} y(t)-\bar{y}& =\sum_{k=-\infty}^{+\infty} c_{k} e^{-i k t} \\ c_{k}& =\frac{1}{2 \pi} \int_{-T/2}^{T/2} (y(t)-\bar{y}) e^{i k t} d t\end{aligned}
$$
>   因此根据中值定理，PSD在$k$附近的积分值与第$k$个振动模式的功率近似相等
>
$$
\frac{\left|c_{k}\right|^{2}}{T} \approx \frac{1}{2\pi }\int_{k-\frac{1}{2}}^{k+\frac{1}{2}} S_{y}(\omega) d \omega
$$
>   这就是\myemph{功率谱密度的物理含义} 。移除了期望的原因是物理量的振幅而非绝对值决定了功率，由于时域上常数的Fourier变换是$\delta$函数，这样做相当于移除了PSD在原点的奇性。在实际问题中，通常可以假设噪声的期望是零。
>   利用 Paseval 恒等式，以及关联函数的时间平均定义，功率谱密度可以改写成关联函数的傅里叶变换\footnote{独立地定义关联函数和功率谱密度，宽平稳随机过程的自关联函数和功率谱的关系称为Wiener-Kinchin定理，在假设级数收敛性良好的情况下，这个定理只不过是 Paseval 恒等式。}
>
$$
\lim \limits_{T \rightarrow \infty} \frac{1}{2\pi T}\left|\hat{y}_{T}(\omega)\right|^{2}=\int_{-\infty}^{\infty}\left[\lim \limits_{T \rightarrow \infty} \frac{1}{2\pi T} \int_{-\infty}^{\infty} (y_T(t-\tau)-\bar{y})  (y_T(t)-\bar{y}) d t\right] e^{-i \omega \tau} d \tau\equiv \frac{1}{2\pi }\int_{-\infty}^{\infty} C_y(\tau) e^{-i \omega \tau} d \tau
$$
>   其中$y_T(t)=y(t)w_T(t)$，$w(t)$是窗口函数。根据上式和关联函数的系综平均定义\footnote{对具有遍历性的随机过程，两种定义是一致的}，PSD还可以写成随机过程的Fourier变换的平方平均
>
$$
S_{y}(\omega)= \frac{1}{2\pi}\int_{-\infty}^{\infty} C_y(\tau) e^{-i \omega \tau} d \tau=\frac{1}{2\pi}\int\left\langle\hat{y}(\omega) \hat{y}^{*}\left(\omega^{\prime}\right)\right\rangle d \omega^{\prime}
$$
>
>   eq-eq-fourierPSD

下面给出共轭对称函数的傅里叶变换的性质
- 定义：
$$
\widehat{f}(\omega) = \int_{-\infty}^{\infty} f(t)\,e^{-i2\pi \omega t}\,dt
$$
- **共轭对称性**：若 $f$ 是实值函数，则其傅里叶变换满足

$$
\widehat{f}(-\omega) = \bigl[\widehat{f}(\omega)\bigr]^*
$$
 上式就是在说，频域实部为偶函数，虚部为奇函数。

- 特殊情况：
  - **实值偶函数** → 傅里叶变换是实值且偶函数。
  - **实值奇函数** → 傅里叶变换是纯虚且奇函数。

反之，如果一个函数的实部为偶函数，虚部为奇函数，例如量子光学中的关联函数，那么它的傅里叶变换就是实值函数，虚部为零。具体来说：
- 定义关联函数：
$$
\tilde{C}_{ab}(t) = \mathrm{Tr}_B\bigl[F_a^B(t)\,F_b^B(0)\,\rho_{\mathrm{eq}}^B\bigr]
$$
  描述环境算符在热平衡下的时间相关性。
- **共轭对称性**：

$$
\tilde{C}_{BA}(-t) = \bigl[\tilde{C}_{AB}(t)\bigr]^*
$$

  这源自环境处于热平衡状态、算符为 Hermitian，以及平衡态下的时间对称性。
### 马尔科夫过程 Markov Process
春天，落樱如梦如忆如思，如翻飞的初雪，如远去的自帆.它们神秘的命运，藏在哪里?

晚秋，斑斓的树叶脱离了树干，在风中起舞.它飞向了何方?它将飞向何方?

还有迷离的细雨，忧愁的柳絮，飘然而至的那一只蝴蝶……这些物体的运
动，都有一个共同的特点，即现在的位置确定之后，过去的历程无法影响未来的运
动，而未来的运动只与现在的状态有关： 恰便似从前种种譬如昨日死，以后种种譬
如今日生[[Renjiagang2021\|Renjiagang2021]].
$$
P_{n+1}\left(X_{n+1}=x \mid X_1=x_1, X_2=x_2, \ldots, X_n=x_n\right)=P_2\left(X_{n+1}=x \mid X_n=x_n\right)
$$
（这个定义是不是有问题？）马尔科夫过程不但是无记忆的，也是没有预见性的，可以用时间反演对称的方式来定义马尔科夫过程，给定当前的状态，过去和将来是相互独立的，即
$$
\begin{array}{c}P_{(n \mid 1)}\left(y_{n}, t_{n} ; \dots ; y_{1}, t_{1} \mid y_{i}, t_{i}\right)=P_{(n-i \mid 1)}\left(y_{n}, t_{n} ; \dots ; y_{i+1}, t_{i+1} \mid y_{i}, t_{i}\right) \\ P_{(i-1 \mid 1)}\left(y_{i-1}, t_{i-1} ;\dots; y_{1}, t_{1} \mid y_{i}, t_{i}\right)\end{array}
$$
**时齐**马尔科夫过程对任意的$n$满足
$$
P_2\left(X_{n+1}=x \mid X_{n}=y\right)= P_2\left(X_{n}=x \mid X_{n-1}=y\right)
$$
即转移概率与$n$无关。 
**平稳**的马尔科夫过程对任意的$n$和$k$满足
$$
P\left(X_{0}=x_{0}, X_{1}=x_{1}, \ldots, X_{k}=x_{k}\right)=P\left(X_{n}=x_{0}, X_{n+1}=x_{1}, \ldots, X_{n+k}=x_{k}\right)
$$
> [!note]
> - 显然，平稳必时齐。反之，对于时齐马尔科夫链，初态是马尔科夫链的稳态分布等价于马尔科夫链是平稳的。

> [!theorem] Theorem  Doob's Theorem（[[doob1942brownian,thorne2017modern\|doob1942brownian,thorne2017modern]] Ex.6.5）
>   任意的严平稳高斯马尔科夫过程的关联函数$C_{y}(\tau)$, 谱密度 $s_{y}(\omega)$, 概率密度 $P_{1}(y)=P_1(y,\tau)$\footnote{对严平稳过程，概率分布与时间无关，联合分布具有平移不变性。由于限制了Gauss性，宽平稳等价于严平稳（？）。下标1表示一阶“关联”。} 以及条件概率密度$P_{2}\left(y_{2}, \tau  | y_{1}\right)=\frac{P_{2}\left(y_{2}, \tau  ; y_{1},0\right)}{P_1(y_1)}$ \footnote{任意平稳随机过程满足$\lim_{\tau \rightarrow 0}=P_{2}\left(y_{2}, \tau  | y_{1}\right)=\delta(y_2-y_1)$（证明？）。下标2表示二阶关联。}具有以下形式：
>
$$
\begin{aligned}
C_{y}(\tau) & =\sigma_{y}^{2} e^{-|\tau| / \tau_{r}} \\
S_{y}(\omega) & =\frac{1}{2\pi }\int_{-\infty}^{\infty} C_y(\tau) e^{-i \omega \tau} d \tau =\frac{1}{\pi}\frac{ \tau_{r}^{-1} \sigma_{y}^{2}}{\omega^{2}+\tau_{r}^{-2}} \\
P_{1}(y) & =\frac{1}{\sqrt{2 \pi \sigma_{y}^{2}}} e^{-(y-\bar{y})^{2} / 2 \sigma_{y}^{2}} \\
P_{2}\left(y_{2}, \tau  | y_{1}\right) & =\frac{1}{\sqrt{2 \pi\left(1-e^{-2 \tau / \tau_{r}}\right) \sigma_{y}^{2}}} \exp \left\{-\frac{\left[\left(y_{2}-\bar{y}\right)-e^{-\tau / \tau_{r}}\left(y_{1}-\bar{y}\right)\right]^{2}}{2\left(1-e^{-2 \tau / \tau_{r}}\right) \sigma_{y}^{2}}\right\},
\end{aligned}
$$
>   其中 $\bar{y}$ 表示均值, $\sigma_{y}$ 是标准差， $\tau_{r}$ 是弛豫时间。
>
>   定理中的随机过程是严平稳的高斯马尔科夫过程，称为**Ornstein–Uhlenbeck过程**。

> [!proof]
> - 只要证明$\sigma_y=1$，$\bar{y}=0$的情形。关键是解出双变量高斯分布的关联函数的具体形式。
>
$$
\begin{aligned}
& P_1(y)=\frac{1}{\sqrt{2 \pi}} e^{-\frac{y^2}{2}} \\
& P_2\left(y_2, t_2, y_1, t_1\right)=\frac{1}{2 \pi \sqrt{1-\rho^2}} \exp \left(-\frac{1}{2\left(1-\rho^2\right)}\left(y_1^2+y_2^2-2 \rho y_1 y_2\right)\right) \\
& \tau=t_2-t_1, \quad \rho\left(t_1, t_2\right)=\int \frac{P_2\left(y_2, t_2 \mid y_1, t_1\right)}{p_1\left(y_1\right)} y_1 y_2 d y_1 d y_2 \\
& =\int \frac{P_2\left(y_2, \tau \mid y_1, 0\right)}{P\left(y_1\right)} y_1 y_2 d y_1 d y_2 \\
& =\rho(\tau) \\
& P_2\left(y_2, t_2 \mid y_1, t_1\right)=\frac{P_2\left(y_2, t_2, y_1, t_1\right)}{P\left(y_1, t_1\right)}=\frac{1}{\sqrt{2 \pi\left(1-\rho^2\right)}} \exp \left(\frac{\left(y_2-y_1 \rho\right)^2}{2\left(\rho^2-1\right)}\right) \\
& P_3\left(y_3, t_3, y_2, t_2, y_1, t_1\right)=P_3\left(y_3, t_3 \mid y_2, t_2, y_1, t_1\right) P_2\left(y_2, t_2, y_1, t_1\right) \\
=&P_2\left(y_3, t_3 \mid y_2, t_2\right) P_2\left(y_2, t_2, y_1, t_1\right) \\
\Rightarrow &\rho \left(t_3-t_1\right)=\int P_3\left(y_3, t_3, y_2, t_2, y_1 t_1\right) y_1 y_3 d y_1 d y_3 d y_2 \\
=&\int P_2\left(y_3, t_3 \mid y_2, t_2\right) P_2\left(y_2, t_2, y_1, t_1\right) y_1 y_3 d y_1 d y_2 d y_3 \\
=&\rho\left(t_3-t_2\right) \rho\left(t_2-t_1\right) \\
& \rho\left(t_3\right)=\rho\left(t_3 - t_2\right) \rho\left(t_2\right) \\
& \rho(t+d t)=\rho(d t) \rho(t) \\
& \frac{\rho(t+d t)-\rho(t)}{d t}=\frac{(\rho(d t)-1) \rho(t)}{d t} \\
& \rho^{\prime}(t)=\rho^{\prime}(0) \rho(t) \quad \rho(0)=1 . \\
& \rho(t)=e^{\rho^{\prime}(0) t} \equiv e^{-\frac{t}{\tau_r}} \\
&
\end{aligned}
$$
>   积分过程参见：高斯分布.nb。

> [!note]
> - 当观察到一个严平稳噪声的频谱或者关联函数偏离上述形式，就可以判定这个过程不是高斯马尔科夫过程。当弛豫时间$\tau_{r}$ 趋于零时，这个过程是一个白噪声。带颜色的噪声未必非马尔可夫，白噪声一定是马尔科夫的\footnote{如何证明？也存在一些不同的看法[[Szankowski2017spectroscopy,fulinski1994NonMarkovianNoise\|Szankowski2017spectroscopy,fulinski1994NonMarkovianNoise]]}。
>   非高斯随机过程的特征往往体现在更高阶的关联中。
>   可以认为尘埃在恒温大气中的布朗运动的各个速度分量都是高斯马尔科夫过程，$\bar{v}=0,\frac{1}{2}m\sigma_y^2= \frac{1}{2}m \overline{v^2}=\frac{1}{2}k_BT,\text{故}\sigma_{v}=\sqrt{k_{B} T / m}$，用涨落耗散定理也可以得到该结论。

> [!proposition]
> - {查普曼-柯尔莫哥洛夫方程 Chapman-Kolmogorov方程}
>   对一般的随机过程CK方程是
>
$$
P_{2}\left(y_{3}, t_{3} | y_{1}, t_{1}\right)=\int P_{3}\left(y_{3}, t_{3} | y_{2}, t_{2} ; y_{1}, t_{1}\right) P_{2}\left(y_{2}, t_{2} | y_{1}, t_{1}\right) d y_{2}
$$
>
>   对于马尔科夫过程，上式简化为
>
$$
P_{2}\left(y_{3}, t_{3} | y_{1}, t_{1}\right)=\int P_{2}\left(y_{3}, t_{3} | y_{2}, t_{2} \right) P_{2}\left(y_{2}, t_{2} | y_{1}, t_{1}\right) d y_{2}
$$
>
>   对严平稳马尔科夫过程，CK方程的形式变得更加有趣
>
$$
P_{2}\left(y_{3}, t_{3} | y_{1},0\right)=\int P_{2}\left(y_{3}, t_{3}-t_{2} | y_{2},0 \right) P_{2}\left(y_{2}, t_{2} | y_{1},0\right) d y_{2}
$$
>
>   eq-eq-markovCK_1
>
>   或者等价地，
>
$$
P_{2}\left(y_{3},\tau_{1} + \tau_{2}| y_{1},0\right)=\int P_{2}\left(y_{3},\tau_{2} | y_{2},0 \right) P_{2}\left(y_{2}, \tau_{1} | y_{1},0\right) d y_{2}
$$
>
>   eq-eq-markovCK_2

> [!proof]
> - 利用条件概率公式易得，见{（[[thorne2017modern\|thorne2017modern]] Sec.6.9.1）}。

> [!note]
> - 马尔科夫过程的任意阶联合分布可以根据初始状态和一组满足CK方程的条件概率$P_2$（作为二阶关联）来描述。平稳的马尔科夫过程的条件概率$P_2$可以记为
>
$$
P_{2}\left(y_{2}, t_{2} \mid y_{1}, t_{1}\right)=T_{t_2-t_1}\left(y_{2}\mid y_{1}\right)
$$
>   $P_{2}$又称为**转移概率**。离散的马尔科夫过程的$n$步转移概率构成一个转移矩阵$p_{ij}^n(n)$，此时，CK方程写成
>
$$
p_{i j}^{(m+n)}=\sum_{k  } p_{i k}^{(m)} p_{k j}^{(n)}
$$

>   考虑到反演的对称性，马尔科夫链可以通过初始分布、向前的一步转移概率和向后的一步转移概率来确定。
>   CK方程\eqref{eq:markovCK_2}反映了马尔科夫过程的半群性质。

马尔科夫过程满足“主方程”
$$
\begin{aligned}P_{1}(y, t+1)&=\sum_{x}\left(P_{2}(y, t+1 \mid x, t) P_{1}(x, t)-P_{2}(x, t+1 \mid y, t) P_{1}(y, t)\right) \\ \frac{\partial P_{1}(y, t)}{\partial t}&=\sum_{x}\left(W\left(y \mid x \right) P_{1}(x, t)-W\left(x \mid y\right) P_1(y, t)\right)\end{aligned}
$$
独立同分布的随机变量构成的随机过程，例如Bernoulli过程，是Markov的，且构成白噪声过程。

## 离散时间鞅
鞅是一种重要的随机过程。在本节中，考虑离散情形，概率空间 $(\Omega, \mathcal{F}, P)$配备了filtration $\left\{\mathcal{F}_{n}\right\}_{n \in \mathbb{T}}$，其中$\mathbb{T}$是正整数或自然数集。
> [!definition]
> - {鞅}
>   实值随机过程$\left\{X_{n}\right\}_{n \in \mathbb{T}}$若满足
>   \begin{enumerate}[(1)]
> - (适应性)$\forall n, \, X_n$是$\mathcal{F}_n$-可测的，即$X$关于$\mathcal{F}_n$是适应过程。
> - (可积性)$\forall n,\, E[|X_m|]<\infty$。
> - (上鞅性)$\forall m \geq n, \,E[X_m|\mathcal{F}_n]\leq X_n \,$almost surely。
>   \end{enumerate}
>   则称$X$为关于filtration $\left\{\mathcal{F}_{n}\right\}_{n \in \mathbb{T}}$的**上鞅(super-)**。如果(3)替换成
>   $\forall m \geq n, \,E[X_m|\mathcal{F}_n]\geq X_n \,$almost surely，则称为**下鞅(sub-)**，如果随机过程既是上鞅又是下鞅，则称为**鞅(martingale)**。

> [!note]
> - 上下鞅的趋势是反直觉的。上鞅被解释为当前值在未来的期望值之上。上鞅向下拉动的趋势比鞅更强，而下鞅向下拉动的趋势比鞅更弱（？）。
>   Martingale一词在统计学历史参见[[mansuy2009origins\|mansuy2009origins]]。

## 连续时间鞅

## 停时的分类

## 循序、可选、可料$\sigma$-代数

## 随机微分方程
在这里我们转向不那么严格的数学[[pavliotis2014stochastic\|pavliotis2014stochastic]]。 
铁三角：Langevin方程、Fokker-Planck方程与伊藤随机微积分。 
$X(t)$是一个$d$维随机向量，它在形式上满足随机微分方程
$$
\frac{d X(t)}{d t}=b(t, X(t))+\sigma(t, X(t)) \xi(t), \quad X(0)=x
$$
其中$\mathbf{f}$是漂移因子，白噪声$\xi(t)=\frac{d W}{d t}$是$m$维空间中的布朗运动的导数，它满足
$$
\mathbb{E}\left(\xi_{i}(t) \xi_{j}(s)\right)=\delta_{i j} \delta(t-s), ~i, j=1, \ldots, m
$$
通常将方程写为
$$
d X(t)=\mathbf{f}(t, X(t)) d t+\sigma(t, X(t)) d W(t)
$$
$$
X(t)=x+\int_{0}^{t} \mathbf{f}(t, X(t)) d t+\int_{0}^{t} \sigma(t, X(t)) d W(t)
$$
随机微分方程理论主要关心下面的几个问题

> [!abstract] Contents
> - 由于布朗运动不是有界变差函数，无法定义Riemann积分，需要考虑如何恰如其分地定义随机积分
$$
I(t):=\int_{0}^{t} \sigma(t, X(t)) d W(t)
$$
> - SDE的解的存在性和唯一性。
> - 计算SDE的解的统计性质、在停时计算解的统计性质。
> - 计算SDE的解的函数（泛函）的统计性质。
> - 将白噪声推广为更一般的噪声。

设$f(s)$是可测空间$(X,\Omega)$上的适应过程，且平方可积，定义
$$
I(t)=\int_{0}^{t} f(s) d W(s):=\lim \limits_{K \rightarrow \infty} \sum_{k=0}^{K-1} f\left(\tau_{k}\right)\left(W\left(t_{k+1}\right)-W\left(t_{k}\right)\right)
$$
其中$t_{k}=k \Delta t, k=0, \ldots, K-1, K \Delta t=t$，$\tau_{k}=(1-\lambda) t_{k}+\lambda t_{k+1}, ~k=0, \ldots, K-1$,$\lambda\in [0,1]$。 
当$\lambda=0$时，定义伊藤随机积分
$$
I_{I}(t):=\lim \limits_{K \rightarrow \infty} \sum_{k=0}^{K-1} f\left(t_{k}\right)\left(W\left(t_{k+1}\right)-W\left(t_{k}\right)\right)
$$
当$\lambda=1/2$时，定义Stratonovich随机积分
$$
I_{S}(t):=\lim \limits_{K \rightarrow \infty} \sum_{k=0}^{K-1} f\left(\frac{1}{2}\left(t_{k}+t_{k+1}\right)\right)\left(W\left(t_{k+1}\right)-W\left(t_{k}\right)\right)
$$
两种积分可以相互转换。 
> [!theorem] 伊藤公式
> - 设$X_t$满足系数不显含时间的伊藤方程
>
$$
d X_{t}=\mathbf{f}\left(X_{t}\right) d t+\sigma\left(X_{t}\right) d W_{t}
$$
>   其中， $V \in C^{1,2}\left([0, T] \times \mathbb{R}^{d}\right)$，那么随机过程$V(X_t)$
>   满足伊藤公式
>
$$
\begin{aligned} V\left(t, X_{t}\right)= & V\left(X_{0}\right)+\int_{0}^{t} \frac{tial V}{\partial s}\left(s, X_{s}\right) d s+\int_{0}^{t} \mathscr{L} V\left(s, X_{s}\right) d s \\ & +\int_{0}^{t}\left\langle\nabla V\left(s, X_{s}\right), \sigma\left(X_{s}\right) d W_{s}\right\rangle  \end{aligned}
$$
>   其中，$\langle\cdot, \cdot\rangle$是$\mathbb{R}^d$上的标准内积，生成元
>
$$
\mathscr{L}=\sum_{j=1}^{d} b_{j}(x) \frac{\partial}{\partial x_{j}}+\frac{1}{2} \sum_{i, j=1}^{d} \Sigma_{i j} \frac{\partial^{2}}{\partial x_{i} \partial x_{j}}
$$
>   **扩散矩阵**
$$
\Sigma(x)=\sigma(x) \sigma(x)^{T}
$$
> [!note]
> - 利用约定 $d W_{i}(t) d W_{j}(t)=\delta_{i j} d t, d W_{i}(t) d t=0$，可以将上面的方程重新写成
>
$$
d V\left(t, X_{t}\right)=\frac{\partial V}{\partial t} d t+\sum_{i=1}^{d} \frac{\partial V}{\partial x_{i}} d X_{i}+\frac{1}{2} \sum_{i, j=1}^{d} \frac{\partial^{2} V}{\partial x_{i} \partial x_{j}} d X_{i} d X_{j}
$$
>   上式可以视为推广的Leibniz法则。
>   证明伊藤公式实际上就是在证明向后Kolmogorov公式{（[[pavliotis2014stochastic\|pavliotis2014stochastic]] Sec.3.4）}，当得到伊藤公式后，向后Kolmogorov公式可以作为简单推论，函数
>
$$
u(x, t)=\mathbb{E} \phi\left(X_{t}^{x}\right):=\mathbb{E}\left(\phi\left(X_{t}^{x}\right) \mid X_{0}^{x}=x\right)
$$
>   满足向后Kolmogorov方程
>
$$
\frac{\partial u}{\partial t}=\mathscr{L} u
$$
### Fokker-Planck方程

> [!proposition] Fokker-Planck方程(向前Kolmogorov方程)
> - \label{prop:fokkerplanck}
>   设$X_t$满足系数不显含时间的伊藤方程
>   $d X_{t}=\mathbf{f}\left(X_{t}\right) d t+\sigma\left(X_{t}\right) d W_{t}$，初始随机变量$X_0$的概率密度为$\rho_0(x)$，那么$p(x,t)$满足Fokker-Planck方程
>
$$
\begin{aligned} \frac{\partial p}{\partial t} & =\mathscr{L}^{*} p \quad \text { for }(x, t) \in \mathbb{R}^{d} \times(0, \infty) \\ p & =\rho_{0} \quad \text { for } x \in \mathbb{R}^{d} \times\{0\}\end{aligned}
$$
>   其中，生成元
>
$$
\mathscr{L}^{*} p =\nabla \cdot\left(-\mathbf{f}(x) p +\frac{1}{2} \nabla \cdot(D p)\right)
$$
> [!proof]
> - 根据向后Kolmogorov方程和分部积分可证{（[[pavliotis2014stochastic\|pavliotis2014stochastic]] Prop.3.3）}。

> [!note]
> - Fokker-Planck方程也可以从马尔科夫过程的CK方程(\ref{eq:markovCK_1})推导出来。

Fokker-Planck方程写成分量形式，有
$$
\frac{\partial p}{\partial t}=-\sum_{i=1}^{d} \frac{\partial}{\partial x_{i}}\left(f_i  p\right)+\frac{1}{2}\sum_{i=1}^{d} \sum_{j=1}^{d} \frac{\partial^{2}}{\partial x_{i} \partial x_{j}}\left(D_{i j} p\right)
$$
定义概率流
$$
\mathbf{J}:=\mathbf{f}(x) p -\frac{1}{2} \nabla \cdot(D  p )
$$
$$
J_{i} =f_i(x) p-\frac{1}{2}\sum_{j=1}^{d}\frac{\partial}{\partial x_{j}} (D_{i j} p(x, t))
$$
可得连续性方程
$$
\frac{\partial p}{\partial t}+\nabla \cdot \mathbf{J}=0
$$
在稳态下$\frac{\partial p}{\partial t}=0$，假设$\mathbf{f}=-\nabla V$，$D$是以$2K$为对角元的对角阵，即$\Sigma_{ij}=2K\delta_{ij}$，则有\footnote{loosely}
$$
p\nabla V=K \nabla p
$$
$$
p=\frac{1}{Z} e^{-V / K}
$$
这是典型的正则分布。

### 熵产生率\label{sec:enproduct}
在系统-环境相互作用中，系统的熵产生速率\footnote{非平衡系统的熵是如何定义的？吉布斯熵？}可以分成两项[[tome2006entropy\|tome2006entropy]]
$$
\frac{d S}{d t}=\Pi-\Phi
$$
其中 $\Pi$是由于系统内部发生的不可逆过程而产生的熵，$\Phi$ 是从系统到环境的熵通量。 $\Pi$ 是正的，而 $\Phi$  不一定。在稳态下熵产生率为零， $\Phi$ = $\Pi$。量 $\Phi$ 定义为从系统内部到外部的通量，因此在非平衡稳态下是正数。 
考虑Fokker-Planck方程，
$$
\frac{\partial p}{\partial t}=-\nabla \cdot \mathbf{J}
$$
其中
$$
J_{i}(x, t)=f_{i}(x) p(x, t)-D_{i} \frac{\partial}{\partial x_{i}} p(x, t)
$$
根据信息熵的定义，可得系统的熵产生率
$$
\frac{d}{d t} S(t)=-\frac{d}{d t}\int p(x, t) \ln p(x, t) d x=\int(\ln p(x, t)+1)\sum_{i} \frac{\partial}{\partial x_{i}} J_{i}(x, t) d x
$$
其中$\partial_tp=-\sum_i\partial _{x_i}J_i$定义了概率流。分部积分
$$
\frac{d}{d t} S(t)=-\int \sum_{i} J_{i}(x, t) \frac{\partial}{\partial x_{i}} \ln p(x, t) d x
$$
当$D_i\ne0$时，根据概率流的定义消去$\mathrm{ln}p$，有
$$
\frac{d}{d t} S(t)=-\int \sum_{i} \frac{1}{D_{i}} J_{i}(x, t) f_{i}(x) d x+\int \sum_{i} \frac{\left[J_{i}(x, t)\right]^{2}}{D_{i} p(x, t)} d x
$$
对照熵产生率的拆分式，有
$$
\Pi=\int \sum_{i} \frac{\left[J_{i}(x, t)\right]^{2}}{D_{i} p(x, t)} d x ,\quad \Phi=\int \sum_{i} \frac{1}{D_{i}} J_{i}(x, t) f_{i}(x) d x=\sum_{i}\left\langle\left(\frac{f_{i}(x)^{2}}{D_{i}}-\frac{\partial f_{i}(x)}{\partial x_{i}}\right)\right\rangle
$$
当$D_i=0$时，
$$
\begin{aligned} \frac{d S}{d t}(t) & =\sum_{i} \int \frac{\partial}{\partial x_{i}}\left(f_{i} p\right)(\ln p+1) d x \\ & =\sum_{i}\left\langle\frac{\partial f_{i}}{\partial x_{i}}\right\rangle+\int \frac{\partial f_{i}}{\partial x^{i}} p \ln p d x-\int\left(\frac{\partial f_{i}}{\partial x_{i}} p(\ln p+1)+f_{i} \frac{\partial p}{\partial x^{i}}\right) d x \\ & =\sum_{i}\left .2\left\langle\frac{\partial f_{i}}{\partial x_{i}}\right\rangle-\int f_{i} \frac{\partial p}{\partial x_{i}} d x\right. \\ & =\sum_{i}\left\langle\frac{\partial f_{i}}{\partial x_{i}}\right\rangle\end{aligned}
$$
### Langevin方程与涨落耗散定理
\label{sec:langevinfdt}
Langevin方程
$$
m \ddot{q}=-\nabla V\left(q\right)-R \dot{q}+\xi
$$

不考虑势能，Langevin方程$m \ddot{q}=-R \dot{q}+\xi(t)$模拟了小颗粒在液体中的运动。
耗散力$-R \dot{q}$和涨落力$\xi(t)$都来自热库，因此他们之间存在关联，涨落耗散定理给出了具体关系，涨落力的功率谱密度\footnote{已经利用$S_\xi(\omega)=\frac{1}{2}\frac{1}{2\pi}S_\xi(f)$，两个因子分别来自双边-单边的差异和频率-角频率转换。}
$$
S_{\xi}(\omega)= \frac{R}{\pi} \left(\frac{1}{2} \hbar \omega+\frac{\hbar \omega}{e^{\hbar \omega/\left(k_{B} T\right)}-1}\right)
$$
在经典极限$k_{B} T \gg \hbar \omega$下
$$
S_{\xi}(\omega)=\frac{R}{\pi}  k_{B} T \quad
$$
> [!proof]
> - {{（[[thorne2017modern\|thorne2017modern]] p323）}}
>   看不懂救命。

> [!note]
> - 由于涨落力的PSD $S_\xi$是常数，故随机过程$\xi$是一个白噪声。根据式\eqref{eq:fourierPSD}可知，关联函数\footnote{此式又一次检验了频率-角频率转换的正确性。}
>
$$
C_\xi(\tau)=  \int_{-\infty}^\infty S_\xi(\omega)e^{i\omega \tau } =2RkT\delta(\tau)
$$
>   将Langevin方程写成关于速度的方程
>
$$
m  \dot{v}   +R v=\xi
$$
>   将上式转换到频域得到传递函数，并应用涨落耗散定理，有
>
$$
S_{v}(\omega)=\frac{S_{\xi}(\omega)}{R^{2}+(\omega m)^{2}}=\frac{1}{ \pi}\frac{  R k_{B} T}{R^{2}+(\omega m)^{2}}
$$
>   与Doob定理\ref{th:doob}中的公式
>
$$
S_{v}(\omega)= \frac{1}{\pi} \frac{\tau_{r}^{-1} \sigma_{v}^{2}}{\omega^{2}+\tau_{r}^{-2}}
$$
>   比较，可以得到反映耗散大小的弛豫时间$\tau_{r}=m / R$，反映涨落大小的速度标准差$\sigma_{v}=\sqrt{k_{B} T / m}$，与前述简单的分析得到相同的结论。

下面，我们用另一种方法从布朗运动的方程推导涨落耗散关系。假设涨落力是一个白噪声。
$$
\langle\xi(t)\rangle=0, \quad\left\langle\xi(t) \xi\left(t^{\prime}\right)\right\rangle=\Gamma \delta\left(t-t^{\prime}\right)
$$
将涨落力看成确定的过程，利用常数变易法求解作为一阶非齐次ODE的布朗运动方程，可得
$$
v(t)=v_{0} e^{- t/\tau_r}+e^{- t/\tau_r} \int_{0}^{t} \frac{e^{ t^{\prime}/\tau_r}}{m} \xi\left(t^{\prime}\right) d t^{\prime}
$$
速度的方差
$$
\operatorname{Var}[v(t)]=\frac{\Gamma\tau_r}{2m^2 }\left(1-e^{-2  t/\tau_r}\right)\rightarrow \frac{\Gamma\tau_r}{2m^2 }=\frac{\Gamma}{2mR}
$$
当$t\gg \tau_r$时，灰尘与水分子达到热平衡
$$
\operatorname{Var}[v(t)]=\frac{k_BT}{m}
$$
比较前面两式可得涨落耗散关系
$$
\Gamma=2Rk_BT
$$
当$t\gg\tau_r$时，速度的自关联函数和PSD为
$$
C_v(t)=\left\langle v(t) v\left(0\right)\right\rangle\rightarrow \frac{\Gamma\tau_r}{2m^2 } e^{-\left|t|/\tau_r\right.}
$$

$$
S_v(\omega)=\frac{\Gamma  }{2 \pi  \left(m^2 \omega^2+R^2\right)}=\frac{1}{2\pi m^2}\frac{2 R k_{B} T}{R^{2}+\omega^2 m^{2}}
$$
与第一种方法所得的结果一致。涨落力也有类似的分析。
在不考虑惯性项$m \mathrm{d} v / \mathrm{d} t$的情况下计算花粉的扩散，设初始位置$q(0)=0$，则有
$$
\begin{aligned}\left\langle q(t)^{2}\right\rangle & =\frac{\tau_{r}^{2}}{m^{2}} \int_{0}^{t} d t_{1} \int_{0}^{t} d t_{2}\left\langle\xi\left(t_{1}\right) \xi\left(t_{2}\right)\right\rangle \\ & =\frac{\Gamma \tau_{r}^{2}}{m^{2}} t\\
    &=\frac{\Gamma}{R^2}t\\&=\frac{2kT}{R}t\end{aligned}
$$
考虑惯性项时\footnote{考虑质量项的扩散.nb}，不失一般性地假设$t_1 >t_2$，
$$
\begin{aligned}&\langle q(t_1)q(t_2)\rangle \\
    =&\frac{1}{m^{2}} \left\langle\int_{0}^{t_{1}} e^{-\frac{k_{2}}{\tau_{1}}} \int_{0}^{k_{2}} e^{\frac{k_{1}}{\tau_{1}}} \xi\left(k_{1}\right) d k_{1} d k_{2} \int_{0}^{t_{2}} e^{-\frac{p_{2}}{\tau_{1}}} \int_{0}^{p_{2}} e^{\frac{p_{1}}{\tau_{r}}} \xi\left(p_{1}\right) d p_{1} d p_{2}\right\rangle \\ 
    =&\frac{\Gamma}{m^{2}} \int_{0}^{t_{1}} d k_{2} \int_{0}^{k_{2}} d k_{1} \int_{0}^{t_{2}} d p_{2} \int_{0}^{p_{2}} d p_{1} e^{\frac{1}{\tau_{r}}\left(k_{1}-k_{2}+p_{1}-p_{2}\right)} \delta\left(k_{1}-p_{1}\right) \\ 
    =&\frac{\Gamma}{m^{2}} \int_{0}^{t_{1}} d k_{2} \int_{0}^{k_{2}} d k_{1} \int_{0}^{t_{2}} d p_{2} e^{\frac{1}{\tau_{r}}\left(2 k_{1}-k_{2}-p_{2}\right)} \theta\left(p_{2}-k_{1}\right) \theta\left(k_{1}\right)\\
    =& -\frac{\Gamma}{m^2}\left(\frac{1}{2} \tau_r^3 e^{\frac{t_2}{\tau_r}-\frac{t_1}{\tau_r}}-\frac{1}{2} \tau_r^3 e^{-\frac{t_1}{\tau_r}-\frac{t_2}{\tau_r}}+\tau_r^3 e^{-\frac{t_2}{\tau_r}}+\tau_r^3 e^{-\frac{t_2}{\tau_r}}+t_1 \tau_r^2-\tau_r^3\right)\\ 
    \rightarrow &\frac{\Gamma  \tau_r^2  }{m^2}t_2 =\frac{\Gamma }{R^2}t_2 \quad(t_1> t_2\gg \tau_r)\end{aligned}
$$
其中$\theta$表示Heaviside函数。 

根据涨落耗散定理，Langevin方程中的涨落项
$$
\xi=\sqrt{\Gamma}\frac{dW}{dt}=\sqrt{{2R k_\mathrm{B} T} }\frac{dW}{dt}
$$
Langevin方程可以写成随机微分方程组
$$
\begin{aligned} d q & =p  d t \\ d p_{t} & =-\nabla V\left(q \right) d t-R p  d t+\sqrt{2 R kT} d W \end{aligned}
$$
